/*******************************************************************************
 * Copyright (c) 2026 Eclipse RDF4J contributors.
 *
 * All rights reserved. This program and the accompanying materials
 * are made available under the terms of the Eclipse Distribution License v1.0
 * which accompanies this distribution, and is available at
 * http://www.eclipse.org/org/documents/edl-v10.php.
 *
 * SPDX-License-Identifier: BSD-3-Clause
 *******************************************************************************/
// Some portions generated by Codex
package org.eclipse.rdf4j.benchmark.common.plan;

import java.io.IOException;
import java.io.InputStream;
import java.nio.charset.StandardCharsets;
import java.nio.file.Files;
import java.nio.file.Path;
import java.time.Instant;
import java.time.ZoneOffset;
import java.time.format.DateTimeFormatter;
import java.util.LinkedHashMap;
import java.util.Locale;
import java.util.Map;
import java.util.Objects;
import java.util.Optional;
import java.util.Set;
import java.util.UUID;
import java.util.concurrent.TimeUnit;
import java.util.function.Function;
import java.util.function.Supplier;
import java.util.stream.Stream;

import org.eclipse.rdf4j.common.annotation.Experimental;
import org.eclipse.rdf4j.query.TupleQuery;
import org.eclipse.rdf4j.query.algebra.TupleExpr;
import org.eclipse.rdf4j.query.explanation.Explanation;

import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.databind.DeserializationFeature;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.SerializationFeature;

/**
 * Captures unoptimized/optimized/executed query explanations and persists snapshot artifacts.
 */
@Experimental
public final class QueryPlanCapture {

	public static final String FORMAT_VERSION = "1";
	public static final String DEFAULT_OUTPUT_DIRECTORY = "testsuites/benchmark/src/main/resources/plan";
	public static final String ENABLE_CAPTURE_PROPERTY = "rdf4j.query.plan.capture.enabled";
	public static final String FEATURE_PROPERTIES_PROPERTY = "rdf4j.query.plan.capture.featureProperties";
	public static final String FEATURE_PROPERTY_PREFIX_PROPERTY = "rdf4j.query.plan.capture.featurePropertyPrefix";
	public static final String GIT_COMMIT_PROPERTY = "rdf4j.query.plan.capture.gitCommit";

	private static final DateTimeFormatter FILE_TIMESTAMP_FORMATTER = DateTimeFormatter
			.ofPattern("yyyyMMdd-HHmmssSSS")
			.withZone(ZoneOffset.UTC);

	private final ObjectMapper snapshotMapper = new ObjectMapper()
			.configure(SerializationFeature.INDENT_OUTPUT, true)
			.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false)
			.setSerializationInclusion(JsonInclude.Include.NON_NULL);
	private final TupleExprJsonCodec tupleExprJsonCodec = new TupleExprJsonCodec();

	public static boolean isCaptureEnabled() {
		return Boolean.parseBoolean(System.getProperty(ENABLE_CAPTURE_PROPERTY, "false"));
	}

	public static Path resolveOutputDirectory() {
		return Path.of(System.getProperty(QueryPlanCaptureContext.OUTPUT_DIRECTORY_PROPERTY,
				DEFAULT_OUTPUT_DIRECTORY));
	}

	public static Map<String, String> metadataFromSystemProperties() {
		LinkedHashMap<String, String> metadata = new LinkedHashMap<>();
		String prefix = QueryPlanCaptureContext.METADATA_PROPERTY_PREFIX;
		System.getProperties()
				.stringPropertyNames()
				.stream()
				.filter(name -> name.startsWith(prefix))
				.sorted()
				.forEach(name -> metadata.put(name.substring(prefix.length()), System.getProperty(name)));
		return metadata;
	}

	public static void registerConfiguredFeatureFlags(FeatureFlagCollector collector) {
		Objects.requireNonNull(collector, "collector");
		collector.addSystemPropertiesFromCsvProperty(FEATURE_PROPERTIES_PROPERTY);
		String prefix = System.getProperty(FEATURE_PROPERTY_PREFIX_PROPERTY);
		if (prefix != null && !prefix.isBlank()) {
			collector.addSystemPropertiesWithPrefix(prefix.trim());
		}
	}

	public QueryPlanSnapshot capture(QueryPlanCaptureContext context,
			Supplier<? extends TupleQuery> tupleQuerySupplier) {
		Objects.requireNonNull(context, "context");
		Objects.requireNonNull(tupleQuerySupplier, "tupleQuerySupplier");

		LinkedHashMap<String, QueryPlanExplanation> explanations = new LinkedHashMap<>();
		for (Explanation.Level level : context.getLevels()) {
			TupleQuery tupleQuery = Objects.requireNonNull(tupleQuerySupplier.get(),
					"tupleQuerySupplier returned null for level " + level);
			Explanation explanation = tupleQuery.explain(level);
			QueryPlanExplanation capturedLevel = captureLevel(level, explanation, context.getIrRenderedLevels(),
					context.getTupleExprRenderer());
			explanations.put(levelKey(level), capturedLevel);
		}

		String fingerprint = resolveUnoptimizedFingerprint(explanations, context.getQueryString());
		LinkedHashMap<String, String> metadata = new LinkedHashMap<>(context.getMetadata());
		if (context.getBenchmark() != null && !context.getBenchmark().isBlank()) {
			metadata.putIfAbsent("benchmark", context.getBenchmark());
		}
		metadata.putIfAbsent("gitCommit", resolveGitCommit());
		metadata.putIfAbsent("javaVersion", System.getProperty("java.version", FeatureFlagCollector.NULL_VALUE));

		FeatureFlagCollector collector = context.getFeatureFlagCollector();
		if (collector != null) {
			registerConfiguredFeatureFlags(collector);
		}
		Map<String, String> featureFlags = collector == null ? Map.of() : collector.snapshot();

		QueryPlanSnapshot snapshot = new QueryPlanSnapshot();
		snapshot.setFormatVersion(FORMAT_VERSION);
		snapshot.setCapturedAt(Instant.now().toString());
		snapshot.setQueryId(context.getQueryId());
		snapshot.setQueryString(context.getQueryString());
		snapshot.setUnoptimizedFingerprint(fingerprint);
		snapshot.setMetadata(metadata);
		snapshot.setFeatureFlags(featureFlags);
		snapshot.setExplanations(explanations);

		return snapshot;
	}

	public Path captureAndWrite(QueryPlanCaptureContext context, Supplier<? extends TupleQuery> tupleQuerySupplier)
			throws IOException {
		QueryPlanSnapshot snapshot = capture(context, tupleQuerySupplier);
		Path outputDirectory = context.getOutputDirectory();
		Files.createDirectories(outputDirectory);

		String fingerprint = snapshot.getUnoptimizedFingerprint();
		String queryId = context.getQueryId() == null ? "query" : context.getQueryId();
		String fileName = sanitizeForFileName(queryId) + "-" + fingerprint + "-"
				+ FILE_TIMESTAMP_FORMATTER.format(Instant.now()) + "-" + UUID.randomUUID().toString().substring(0, 8)
				+ ".json";

		Path outputFile = outputDirectory.resolve(fileName);
		writeSnapshot(outputFile, snapshot);
		return outputFile;
	}

	public void writeSnapshot(Path outputFile, QueryPlanSnapshot snapshot) throws IOException {
		Objects.requireNonNull(outputFile, "outputFile");
		Objects.requireNonNull(snapshot, "snapshot");
		Path parent = outputFile.getParent();
		if (parent != null) {
			Files.createDirectories(parent);
		}
		snapshotMapper.writeValue(outputFile.toFile(), snapshot);
	}

	public QueryPlanSnapshot readSnapshot(Path inputFile) throws IOException {
		Objects.requireNonNull(inputFile, "inputFile");
		return snapshotMapper.readValue(inputFile.toFile(), QueryPlanSnapshot.class);
	}

	public Optional<Path> findByUnoptimizedFingerprint(Path directory, String unoptimizedFingerprint)
			throws IOException {
		Objects.requireNonNull(directory, "directory");
		Objects.requireNonNull(unoptimizedFingerprint, "unoptimizedFingerprint");
		if (!Files.exists(directory)) {
			return Optional.empty();
		}

		try (Stream<Path> paths = Files.walk(directory)) {
			return paths.filter(Files::isRegularFile)
					.filter(path -> path.getFileName().toString().contains(unoptimizedFingerprint))
					.findFirst();
		}
	}

	private QueryPlanExplanation captureLevel(Explanation.Level level, Explanation explanation,
			Set<Explanation.Level> irRenderedLevels, Function<TupleExpr, String> tupleExprRenderer) {
		QueryPlanExplanation captured = new QueryPlanExplanation();
		captured.setLevel(level.name());
		captured.setExplanationText(explanation.toString());
		captured.setExplanationJson(explanation.toJson());

		Object tupleExprObject = explanation.tupleExpr();
		if (tupleExprObject instanceof TupleExpr) {
			TupleExpr tupleExpr = ((TupleExpr) tupleExprObject).clone();
			captured.setTupleExprTree(tupleExpr.toString());
			captured.setTupleExprJson(tupleExprJsonCodec.toJson(tupleExpr));
			if (irRenderedLevels.contains(level)) {
				renderWithIr(tupleExpr, tupleExprRenderer, captured);
			}
		}

		return captured;
	}

	private void renderWithIr(TupleExpr tupleExpr, Function<TupleExpr, String> tupleExprRenderer,
			QueryPlanExplanation target) {
		if (tupleExprRenderer == null) {
			target.setIrRenderingError("No tuple expression renderer configured");
			return;
		}
		try {
			target.setIrRenderedQuery(tupleExprRenderer.apply(tupleExpr));
		} catch (Exception e) {
			target.setIrRenderingError(e.getClass().getSimpleName() + ": " + e.getMessage());
		}
	}

	private String resolveUnoptimizedFingerprint(Map<String, QueryPlanExplanation> explanations, String queryString) {
		QueryPlanExplanation unoptimized = explanations.get(levelKey(Explanation.Level.Unoptimized));
		if (unoptimized != null) {
			if (unoptimized.getTupleExprJson() != null && !unoptimized.getTupleExprJson().isBlank()) {
				return tupleExprJsonCodec.fingerprintFromJson(unoptimized.getTupleExprJson());
			}
			if (unoptimized.getTupleExprTree() != null && !unoptimized.getTupleExprTree().isBlank()) {
				return tupleExprJsonCodec.fingerprintFromText(unoptimized.getTupleExprTree());
			}
		}
		if (queryString != null && !queryString.isBlank()) {
			return tupleExprJsonCodec.fingerprintFromText(queryString);
		}
		return UUID.randomUUID().toString().replace("-", "");
	}

	private static String levelKey(Explanation.Level level) {
		return level.name().toLowerCase(Locale.ROOT);
	}

	private static String sanitizeForFileName(String input) {
		return input.replaceAll("[^a-zA-Z0-9._-]", "_");
	}

	private static String resolveGitCommit() {
		String configured = System.getProperty(GIT_COMMIT_PROPERTY);
		if (configured != null && !configured.isBlank()) {
			return configured.trim();
		}

		String fromEnvironment = System.getenv("GIT_COMMIT");
		if (fromEnvironment != null && !fromEnvironment.isBlank()) {
			return fromEnvironment.trim();
		}

		Process process = null;
		try {
			process = new ProcessBuilder("git", "rev-parse", "--verify", "HEAD")
					.redirectErrorStream(true)
					.start();
			boolean finished = process.waitFor(2, TimeUnit.SECONDS);
			if (!finished || process.exitValue() != 0) {
				return "unknown";
			}
			try (InputStream stream = process.getInputStream()) {
				String output = new String(stream.readAllBytes(), StandardCharsets.UTF_8)
						.trim();
				return output.isEmpty() ? "unknown" : output;
			}
		} catch (Exception ignored) {
			return "unknown";
		} finally {
			if (process != null) {
				process.destroyForcibly();
			}
		}
	}
}
